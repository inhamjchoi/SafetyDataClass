{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inhamjchoi/SafetyDataClass/blob/main/Ex06_1_Practice_1_ACC_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qovgLrVIy2n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.signal import find_peaks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_from_window(data_x, data_y, data_z):\n",
        "    \"\"\"\n",
        "    Extract features from a single window of X, Y, Z data\n",
        "\n",
        "    Args:\n",
        "        data_x, data_y, data_z: 1D arrays of window data\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing features for this window\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "\n",
        "    # Time domain features\n",
        "    features['MeanX'] = np.mean(data_x)\n",
        "    features['MeanY'] = np.mean(data_y)\n",
        "    features['MeanZ'] = np.mean(data_z)\n",
        "\n",
        "    features['SkewX'] = stats.skew(data_x)\n",
        "    features['SkewY'] = stats.skew(data_y)\n",
        "    features['SkewZ'] = stats.skew(data_z)\n",
        "\n",
        "    features['MaxX'] = np.max(data_x)\n",
        "    features['MaxY'] = np.max(data_y)\n",
        "    features['MaxZ'] = np.max(data_z)\n",
        "\n",
        "    features['MinX'] = np.min(data_x)\n",
        "    features['MinY'] = np.min(data_y)\n",
        "    features['MinZ'] = np.min(data_z)\n",
        "\n",
        "    features['RangeX'] = np.max(data_x) - np.min(data_x)\n",
        "    features['RangeY'] = np.max(data_y) - np.min(data_y)\n",
        "    features['RangeZ'] = np.max(data_z) - np.min(data_z)\n",
        "\n",
        "    features['StdX'] = np.std(data_x, ddof=1)\n",
        "    features['StdY'] = np.std(data_y, ddof=1)\n",
        "    features['StdZ'] = np.std(data_z, ddof=1)\n",
        "\n",
        "    features['KurtosisX'] = stats.kurtosis(data_x, fisher=False)\n",
        "    features['KurtosisY'] = stats.kurtosis(data_y, fisher=False)\n",
        "    features['KurtosisZ'] = stats.kurtosis(data_z, fisher=False)\n",
        "\n",
        "    # Average peak distance\n",
        "    peaks_x, _ = find_peaks(data_x)\n",
        "    if len(peaks_x) > 1:\n",
        "        features['Avg_peak_distX'] = np.mean(np.diff(peaks_x))\n",
        "    else:\n",
        "        features['Avg_peak_distX'] = 0\n",
        "\n",
        "    peaks_y, _ = find_peaks(data_y)\n",
        "    if len(peaks_y) > 1:\n",
        "        features['Avg_peak_distY'] = np.mean(np.diff(peaks_y))\n",
        "    else:\n",
        "        features['Avg_peak_distY'] = 0\n",
        "\n",
        "    peaks_z, _ = find_peaks(data_z)\n",
        "    if len(peaks_z) > 1:\n",
        "        features['Avg_peak_distZ'] = np.mean(np.diff(peaks_z))\n",
        "    else:\n",
        "        features['Avg_peak_distZ'] = 0\n",
        "\n",
        "    # Correlations\n",
        "    features['CorrXY'] = np.corrcoef(data_x, data_y)[0, 1]\n",
        "    features['CorrYZ'] = np.corrcoef(data_y, data_z)[0, 1]\n",
        "    features['CorrZX'] = np.corrcoef(data_z, data_x)[0, 1]\n",
        "\n",
        "    # Frequency domain features\n",
        "    # Sampling frequency for ACC1\n",
        "    fs = 32  # Hz\n",
        "    window_length = len(data_x)\n",
        "\n",
        "    # Energy calculation\n",
        "    def compute_energy(signal):\n",
        "        # Remove DC component\n",
        "        new_signal = signal - np.mean(signal)\n",
        "        # Zero-pad to next power of 2\n",
        "        n = 2 ** int(np.ceil(np.log2(window_length)))\n",
        "        # Compute FFT\n",
        "        dft = np.fft.fft(new_signal, n)\n",
        "        # Power spectrum (one-sided)\n",
        "        power = np.abs(dft[:n//2])**2 / n\n",
        "        return np.sum(power)\n",
        "\n",
        "    features['EnergyX'] = compute_energy(data_x)\n",
        "    features['EnergyY'] = compute_energy(data_y)\n",
        "    features['EnergyZ'] = compute_energy(data_z)\n",
        "\n",
        "    # Entropy calculation\n",
        "    def compute_entropy(signal):\n",
        "        # Zero-pad to next power of 2\n",
        "        n = 2 ** int(np.ceil(np.log2(window_length)))\n",
        "        # Compute FFT\n",
        "        dft = np.fft.fft(signal, n)\n",
        "        # Power spectrum (one-sided)\n",
        "        power = np.abs(dft[:n//2])**2 / n\n",
        "        # Normalize\n",
        "        temp = power - np.min(power)\n",
        "        if np.max(temp) - np.min(temp) == 0:\n",
        "            return 0\n",
        "        norm_pow = 1e-12 + temp / (np.max(temp) - np.min(temp))\n",
        "        # Entropy\n",
        "        entropy = -np.sum(norm_pow * np.log2(norm_pow + 1e-12))\n",
        "        return entropy\n",
        "\n",
        "    features['EntropyX'] = compute_entropy(data_x)\n",
        "    features['EntropyY'] = compute_entropy(data_y)\n",
        "    features['EntropyZ'] = compute_entropy(data_z)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "5r3Z_ymeKwxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"=== ACC1.csv 1-Second Window Feature Extraction ===\\n\")\n",
        "\n",
        "    # Read accelerometer data from ACC1.csv\n",
        "    # - The first row contains the recording start time (not needed for analysis)\n",
        "    # - The second row contains the sampling frequency in Hz (32 Hz)\n",
        "    # - We skip both using `skiprows=2`\n",
        "    # - The actual sensor data starts from the 3rd row onward (acceleration in X, Y, Z)\n",
        "    df = pd.read_csv('ACC1.csv', header=None, skiprows=2)\n",
        "\n",
        "    # Rename columns to indicate axis of acceleration\n",
        "    df.columns = ['X', 'Y', 'Z']\n",
        "\n",
        "    # Preview the first few rows\n",
        "    print(\"Raw data preview:\")\n",
        "    print(df.head())\n",
        "    print(f\"Data shape: {df.shape}\")\n",
        "\n",
        "    # Extract raw data for each axis\n",
        "    rawdata_x = df['X'].values\n",
        "    rawdata_y = df['Y'].values\n",
        "    rawdata_z = df['Z'].values\n",
        "\n",
        "    print(f\"\\nData lengths:\")\n",
        "    print(f\"Total data points: {len(rawdata_x)}\")\n",
        "\n",
        "    print(f\"\\nData ranges:\")\n",
        "    print(f\"X: {np.min(rawdata_x):.3f} to {np.max(rawdata_x):.3f}\")\n",
        "    print(f\"Y: {np.min(rawdata_y):.3f} to {np.max(rawdata_y):.3f}\")\n",
        "    print(f\"Z: {np.min(rawdata_z):.3f} to {np.max(rawdata_z):.3f}\")\n",
        "\n",
        "    print(f\"\\nBasic statistics:\")\n",
        "    print(f\"Mean - X: {np.mean(rawdata_x):.3f}, Y: {np.mean(rawdata_y):.3f}, Z: {np.mean(rawdata_z):.3f}\")\n",
        "    print(f\"Std  - X: {np.std(rawdata_x):.3f}, Y: {np.std(rawdata_y):.3f}, Z: {np.std(rawdata_z):.3f}\")\n",
        "\n",
        "    # Window parameters\n",
        "    sampling_rate = 32  # Hz\n",
        "    window_duration = 1  # seconds\n",
        "    window_size = sampling_rate * window_duration  # 32 * 1 = 32 data points\n",
        "\n",
        "    print(f\"\\nWindow parameters:\")\n",
        "    print(f\"Sampling rate: {sampling_rate} Hz\")\n",
        "    print(f\"Window duration: {window_duration} seconds\")\n",
        "    print(f\"Window size: {window_size} data points\")\n",
        "\n",
        "    # Calculate number of windows (no overlap)\n",
        "    total_data_points = len(rawdata_x)\n",
        "    num_windows = total_data_points // window_size\n",
        "\n",
        "    print(f\"Total data points: {total_data_points}\")\n",
        "    print(f\"Number of 1-second windows: {num_windows}\")\n",
        "    print(f\"Data points used: {num_windows * window_size}\")\n",
        "    print(f\"Data points remaining: {total_data_points - (num_windows * window_size)}\")\n",
        "\n",
        "    # Create 1-second windows (no overlap)\n",
        "    print(f\"\\nCreating 1-second windows...\")\n",
        "\n",
        "    windows_x = []\n",
        "    windows_y = []\n",
        "    windows_z = []\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start_idx = i * window_size\n",
        "        end_idx = start_idx + window_size\n",
        "\n",
        "        # Extract window data\n",
        "        window_x = rawdata_x[start_idx:end_idx]\n",
        "        window_y = rawdata_y[start_idx:end_idx]\n",
        "        window_z = rawdata_z[start_idx:end_idx]\n",
        "\n",
        "        windows_x.append(window_x)\n",
        "        windows_y.append(window_y)\n",
        "        windows_z.append(window_z)\n",
        "\n",
        "    print(f\"Created {len(windows_x)} windows of {window_size} points each\")\n",
        "\n",
        "    # Initialize results storage\n",
        "    results = []\n",
        "\n",
        "    print(f\"\\nExtracting features from each 1-second window...\")\n",
        "\n",
        "    # Process each 1-second window\n",
        "    for i in range(num_windows):\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Processing window {i+1}/{num_windows}...\")\n",
        "\n",
        "        # Get window data\n",
        "        data_x = windows_x[i]\n",
        "        data_y = windows_y[i]\n",
        "        data_z = windows_z[i]\n",
        "\n",
        "        # Extract features for this window\n",
        "        features = extract_features_from_window(data_x, data_y, data_z)\n",
        "\n",
        "        # Add window information\n",
        "        features['Window_ID'] = i + 1\n",
        "        features['Time_Start'] = i * window_duration  # Start time in seconds\n",
        "        features['Time_End'] = (i + 1) * window_duration  # End time in seconds\n",
        "\n",
        "        results.append(features)\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    feature_names = ['MeanX', 'MeanY', 'MeanZ', 'SkewX', 'SkewY', 'SkewZ',\n",
        "                     'MaxX', 'MaxY', 'MaxZ', 'MinX', 'MinY', 'MinZ',\n",
        "                     'RangeX', 'RangeY', 'RangeZ', 'StdX', 'StdY', 'StdZ',\n",
        "                     'KurtosisX', 'KurtosisY', 'KurtosisZ',\n",
        "                     'Avg_peak_distX', 'Avg_peak_distY', 'Avg_peak_distZ',\n",
        "                     'CorrXY', 'CorrYZ', 'CorrZX',\n",
        "                     'EnergyX', 'EnergyY', 'EnergyZ',\n",
        "                     'EntropyX', 'EntropyY', 'EntropyZ',\n",
        "                     'Window_ID', 'Time_Start', 'Time_End']\n",
        "\n",
        "    all_result = pd.DataFrame(results, columns=feature_names)\n",
        "\n",
        "    print(f\"\\n=== Feature Extraction Complete ===\")\n",
        "    print(f\"Total windows processed: {len(all_result)}\")\n",
        "    print(f\"Features per window: 33 + 3 metadata columns\")\n",
        "\n",
        "    # Display sample results\n",
        "    print(f\"\\nSample of extracted features:\")\n",
        "    display_cols = ['Window_ID', 'Time_Start', 'Time_End', 'MeanX', 'MeanY', 'MeanZ', 'StdX', 'StdY', 'StdZ']\n",
        "    print(all_result[display_cols].head().round(4))\n",
        "\n",
        "    # Display some statistics\n",
        "    print(f\"\\nFeature statistics (first few features):\")\n",
        "    stats_cols = ['MeanX', 'MeanY', 'MeanZ', 'StdX', 'StdY', 'StdZ']\n",
        "    print(all_result[stats_cols].describe().round(4))\n",
        "\n",
        "    # Save results to CSV\n",
        "    output_file = 'ACC1_1second_windows_features.csv'\n",
        "    all_result.to_csv(output_file, index=False)\n",
        "    print(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "    # Additional summary\n",
        "    print(f\"\\n=== Summary ===\")\n",
        "    print(f\"Original data points: {total_data_points}\")\n",
        "    print(f\"Sampling rate: {sampling_rate} Hz\")\n",
        "    print(f\"Window duration: {window_duration} seconds\")\n",
        "    print(f\"Window size: {window_size} data points\")\n",
        "    print(f\"Total windows: {num_windows}\")\n",
        "    print(f\"Total recording time: {total_data_points/sampling_rate:.1f} seconds\")\n",
        "    print(f\"Analyzed time: {num_windows * window_duration} seconds\")\n",
        "    print(f\"Features per window: 33\")\n",
        "    print(f\"Output file: {output_file}\")\n",
        "\n",
        "    print(\"\\n=== Processing Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39NM41iK0uk",
        "outputId": "eda41135-7ea6-4685-e97b-d0aecd88912e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ACC1.csv 1-Second Window Feature Extraction ===\n",
            "\n",
            "Raw data preview:\n",
            "   X   Y   Z\n",
            "0 -2  59  29\n",
            "1  4  57  29\n",
            "2  2  59  28\n",
            "3  2  60  29\n",
            "4  2  60  31\n",
            "Data shape: (177, 3)\n",
            "\n",
            "Data lengths:\n",
            "Total data points: 177\n",
            "\n",
            "Data ranges:\n",
            "X: -32.000 to 126.000\n",
            "Y: -7.000 to 93.000\n",
            "Z: -82.000 to 70.000\n",
            "\n",
            "Basic statistics:\n",
            "Mean - X: 17.458, Y: 51.582, Z: 15.537\n",
            "Std  - X: 21.988, Y: 17.479, Z: 24.560\n",
            "\n",
            "Window parameters:\n",
            "Sampling rate: 32 Hz\n",
            "Window duration: 1 seconds\n",
            "Window size: 32 data points\n",
            "Total data points: 177\n",
            "Number of 1-second windows: 5\n",
            "Data points used: 160\n",
            "Data points remaining: 17\n",
            "\n",
            "Creating 1-second windows...\n",
            "Created 5 windows of 32 points each\n",
            "\n",
            "Extracting features from each 1-second window...\n",
            "\n",
            "=== Feature Extraction Complete ===\n",
            "Total windows processed: 5\n",
            "Features per window: 33 + 3 metadata columns\n",
            "\n",
            "Sample of extracted features:\n",
            "   Window_ID  Time_Start  Time_End    MeanX    MeanY    MeanZ     StdX  \\\n",
            "0          1           0         1   5.9062  59.0625  27.0625   6.1506   \n",
            "1          2           1         2   9.6875  57.0938  12.7500   6.6451   \n",
            "2          3           2         3  16.9375  60.8438   3.0938  13.7088   \n",
            "3          4           3         4  26.4688  43.7188  27.8125   7.1662   \n",
            "4          5           4         5  30.1875  33.7188  31.4062  40.1902   \n",
            "\n",
            "      StdY     StdZ  \n",
            "0   4.8986   3.6273  \n",
            "1   6.2803  11.2393  \n",
            "2   4.3113   9.3442  \n",
            "3  14.6843  19.7230  \n",
            "4  27.7689  27.0851  \n",
            "\n",
            "Feature statistics (first few features):\n",
            "         MeanX    MeanY    MeanZ     StdX     StdY     StdZ\n",
            "count   5.0000   5.0000   5.0000   5.0000   5.0000   5.0000\n",
            "mean   17.8375  50.8875  20.4250  14.7722  11.5887  14.2038\n",
            "std    10.4476  11.7328  12.0260  14.5382   9.9659   9.2284\n",
            "min     5.9062  33.7188   3.0938   6.1506   4.3113   3.6273\n",
            "25%     9.6875  43.7188  12.7500   6.6451   4.8986   9.3442\n",
            "50%    16.9375  57.0938  27.0625   7.1662   6.2803  11.2393\n",
            "75%    26.4688  59.0625  27.8125  13.7088  14.6843  19.7230\n",
            "max    30.1875  60.8438  31.4062  40.1902  27.7689  27.0851\n",
            "\n",
            "Results saved to: ACC1_1second_windows_features.csv\n",
            "\n",
            "=== Summary ===\n",
            "Original data points: 177\n",
            "Sampling rate: 32 Hz\n",
            "Window duration: 1 seconds\n",
            "Window size: 32 data points\n",
            "Total windows: 5\n",
            "Total recording time: 5.5 seconds\n",
            "Analyzed time: 5 seconds\n",
            "Features per window: 33\n",
            "Output file: ACC1_1second_windows_features.csv\n",
            "\n",
            "=== Processing Complete ===\n"
          ]
        }
      ]
    }
  ]
}